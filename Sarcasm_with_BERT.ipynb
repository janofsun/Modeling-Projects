{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Sarcasm Detection using BERT"
      ],
      "metadata": {
        "id": "6-8aJIUfzuYD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zGUn86ZMzrk2"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import re\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_text\n",
        "from official.nlp import optimization\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import rcParams\n",
        "import keras\n",
        "from keras.layers import Dense\n",
        "from tensorflow.keras.models import model_from_json\n",
        "import math\n",
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "import os\n",
        "\n",
        "tf.get_logger().setLevel('ERROR')\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv('./usercode/train.csv')\n",
        "test = pd.read_csv('./usercode/test.csv')\n",
        "val = pd.read_csv('./usercode/validate.csv')\n",
        "X_train = train[[\"text\"]].copy()\n",
        "X_test = test[[\"text\"]].copy()\n",
        "X_val = val[[\"text\"]].copy()\n",
        "Y_train = train[[\"labels\"]].copy()\n",
        "Y_test = test[[\"labels\"]].copy()\n",
        "Y_val = val[[\"labels\"]].copy()\n",
        "X_train.head()"
      ],
      "metadata": {
        "id": "Eya9hviPzx6z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pre-process Data\n",
        "\n",
        "\n",
        "\n",
        "*   Include only lowercase, alphanumeric characters.\n",
        "*   Are of the string data type.\n",
        "*   Do not contain the rt (retweet) tag.\n",
        "\n"
      ],
      "metadata": {
        "id": "8ZS8xhST0dlS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(data):\n",
        "  data = data.astype(str)\n",
        "  data = data.apply(lambda x: x.lower())\n",
        "  data = data.apply((lambda x: re.sub('[^a-zA-Z0-9\\s]','',x)))\n",
        "\n",
        "  for idx,row in enumerate(data):\n",
        "      row = row.replace('rt',' ')\n",
        "\n",
        "  return data"
      ],
      "metadata": {
        "id": "zNnzLSOmzzr2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train[\"text\"] = preprocess(X_train[\"text\"])\n",
        "X_val[\"text\"] = preprocess(X_val[\"text\"])\n",
        "X_test[\"text\"] = preprocess(X_test[\"text\"])\n",
        "X_train.head()"
      ],
      "metadata": {
        "id": "JDx16kDmz2Cf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Choose the model and its preprocessor"
      ],
      "metadata": {
        "id": "m4oFZO9O0wTF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "keras.backend.clear_session()\n",
        "\n",
        "encoder_url = \"https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-128_A-2/1\"\n",
        "preprocessor_url = \"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\""
      ],
      "metadata": {
        "id": "waMhjpEjz2gA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create the classification model\n",
        "\n",
        "*   An input layer with the name text.\n",
        "*   A preprocessor block created using the hub.KerasLayer() method. This method requires the URL of the preprocessing model as input:\n",
        "*   A BERT encoder retrieved from TensorFlow Hub, using the hub.KerasLayer() method. This method requires the URL of the previously chosen BERT model as input:\n",
        "*   A pooling layer where pooled outputs are extracted from the encoder.\n",
        "*   A Dropout layer.\n",
        "*   A Dense output layer that produces the predictions."
      ],
      "metadata": {
        "id": "pIzMxOu114FP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_classifier_model():\n",
        "  text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
        "  preprocessing_layer = hub.KerasLayer(preprocessor_url, name='preprocessing')\n",
        "  encoder_inputs = preprocessing_layer(text_input)\n",
        "  encoder = hub.KerasLayer(encoder_url, trainable=True, name='BERT_encoder')\n",
        "  outputs = encoder(encoder_inputs)\n",
        "  net = outputs['pooled_output']\n",
        "  net = tf.keras.layers.Dropout(0.2)(net)\n",
        "  net = tf.keras.layers.Dense(2, activation='softmax', name='classifier')(net)\n",
        "  return tf.keras.Model(text_input, net)"
      ],
      "metadata": {
        "id": "2yzXJGyzz5lE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier_model = build_classifier_model()"
      ],
      "metadata": {
        "id": "J_EToBjzz6Eu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs =  4\n",
        "batch_size = 64\n",
        "steps_per_epoch = math.floor(X_train.shape[0]/batch_size)\n",
        "num_train_steps = steps_per_epoch * epochs\n",
        "num_warmup_steps = int(0.1*num_train_steps)\n",
        "init_lr = 3e-5\n",
        "\n",
        "loss = tf.keras.losses.BinaryCrossentropy()\n",
        "\n",
        "metrics = tf.metrics.BinaryAccuracy()\n",
        "\n",
        "optimizer = optimization.create_optimizer(init_lr=init_lr,\n",
        "            num_train_steps=num_train_steps,\n",
        "            num_warmup_steps=num_warmup_steps,\n",
        "            optimizer_type='adamw')"
      ],
      "metadata": {
        "id": "vE-dGwTXz7fO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Option A: Load the trained model"
      ],
      "metadata": {
        "id": "nukaAVO52Y1j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "json_file = open('usercode/model.json', 'r')\n",
        "loaded_model_json = json_file.read()\n",
        "json_file.close()\n",
        "\n",
        "classifier_model = model_from_json(loaded_model_json, custom_objects={'KerasLayer':hub.KerasLayer})\n",
        "\n",
        "classifier_model.load_weights(\"usercode/model.h5\")\n",
        "print(\"Loaded model from disk\")\n",
        "\n",
        "classifier_model.compile(optimizer=optimizer,\n",
        "              loss=loss,\n",
        "              metrics=metrics)"
      ],
      "metadata": {
        "id": "3DDJNhGhz-GE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Option B: Train the model and display the training curve"
      ],
      "metadata": {
        "id": "lEUtEtkU4Rpo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier_model.compile(optimizer=optimizer,\n",
        "                        loss=loss,\n",
        "                        metrics=metrics)\n",
        "history = classifier_model.fit(X_train,\n",
        "pd.get_dummies(Y_train[\"labels\"]),\n",
        "     validation_data=(X_val, pd.get_dummies(Y_val[\"labels\"])),\n",
        "     epochs=epochs, batch_size=batch_size, verbose=1)"
      ],
      "metadata": {
        "id": "fNOTZ-yc0AAt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.rcParams[\"figure.figsize\"] = (12,8)\n",
        "N = np.arange(0, epochs)\n",
        "plt.style.use(\"ggplot\")\n",
        "plt.figure()\n",
        "plt.plot(N, history.history[\"loss\"], label=\"train_loss\")\n",
        "plt.plot(N, history.history[\"val_loss\"], label=\"val_loss\")\n",
        "plt.plot(N, history.history['binary_accuracy'], label=\"binary_accuracy\")\n",
        "plt.plot(N, history.history[\"val_binary_accuracy\"], label=\"val_binary_accuracy\")\n",
        "plt.title(\"Training Loss and Accuracies (Finetuning BERT for Sarcasm Classification)\")\n",
        "plt.xlabel(\"Epoch #\")\n",
        "plt.ylabel(\"Loss/Accuracy\")\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "mfihXQsk0DzN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = classifier_model.evaluate(X_test, pd.get_dummies(Y_test[\"labels\"]))\n",
        "\n",
        "print('Loss: ', loss)\n",
        "print('Accuracy: ', accuracy)\n",
        "\n",
        "actuals = Y_test[\"labels\"]\n",
        "Y_predicted = classifier_model.predict(X_test)\n",
        "predictions= np.argmax(Y_predicted,axis=1)"
      ],
      "metadata": {
        "id": "E5wLe5JL0FP2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(actuals, predictions)\n",
        "\n",
        "plt.figure(figsize=(4,3))\n",
        "sns.heatmap(cm, annot=True, fmt='g')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')"
      ],
      "metadata": {
        "id": "q3bh6ik_0Gcl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_names = ['Non-Sarcastic', \"Sarcastic\"]\n",
        "print(classification_report(actuals, predictions, target_names=target_names))"
      ],
      "metadata": {
        "id": "B450YVeY0KSu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}